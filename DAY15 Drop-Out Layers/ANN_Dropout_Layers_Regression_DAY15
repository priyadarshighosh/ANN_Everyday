{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1RO_zr_tQ3BNsXnC3GhDtgR0KuMPaUI7_","timestamp":1726122299987},{"file_id":"1ahyTCXn-3LXAXyJkvqVyfqNlQ4Eex31M","timestamp":1726057833443},{"file_id":"1sUMvMIQRQaOZ9J_H8sHaj9zr3VH34vdK","timestamp":1725989843585}],"authorship_tag":"ABX9TyMfOcEvCA6V/yPcslx/ym9f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# DROPOUT LAYERS\n","\n","# REGRESSION Implementation"],"metadata":{"id":"buV9E0bf-37g"}},{"cell_type":"markdown","source":["IMPORTING THE DATA SCIENCE LIBRARIES"],"metadata":{"id":"HNvHInaq_BMJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eum2WGOnBeeL"},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import time"]},{"cell_type":"markdown","source":["Importing the ML / Scikit learn EVERYTHING"],"metadata":{"id":"egI1aKHM_G4g"}},{"cell_type":"code","source":["\n","from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n","from sklearn.compose import ColumnTransformer                       #for transforming the columns\n","from sklearn.impute import SimpleImputer                             #for imputing the missing values\n","from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n","from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n","\n","from sklearn.linear_model import LinearRegression                    #linear regression\n","from sklearn.pipeline import Pipeline,make_pipeline                    #here we wont use pipelines\n","\n","from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error     #to calculate the loss function"],"metadata":{"id":"v-A2uAybzaKX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Importing Deep learning Everything"],"metadata":{"id":"7EOOII0y82hE"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"O1qjFngb87Y8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset Generation"],"metadata":{"id":"ADdQQGes_Sdp"}},{"cell_type":"markdown","source":["This is our HAND-MADE DATASET"],"metadata":{"id":"sGKaQv4Ul99C"}},{"cell_type":"code","source":["X_train = np.linspace(-1,1,20)"],"metadata":{"id":"xwa5_8xA7DQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = np.array([-0.6561 , -0.3099 , -0.59035, -0.50855, -0.285  ,\n","                    -0.2443 , -0.02445,  0.00135, -0.2006 ,  0.07475,\n","                    -0.1422 ,  0.06515,  0.15265,  0.3521 ,  0.28415,\n","                    0.5524 ,  0.23115,  0.20835, 0.4211,  0.60485])"],"metadata":{"id":"9wUzb7Hf7Lh_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test = np.linspace(-1,1,20)"],"metadata":{"id":"724zAiSG7Wc0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test = np.array([-0.69415, -0.451  , -0.43005, -0.4484 , -0.1475 ,\n","                   -0.5019 , -0.28055,  0.24595, -0.21425, -0.0286 ,\n","                   0.23415,  0.46575, 0.07955,  0.1973 ,  0.0719 ,\n","                   0.3639 ,  0.5536 ,  0.3365 , 0.50705,  0.33435])"],"metadata":{"id":"byR4dqSf7mgP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plotting the graph of the following data"],"metadata":{"id":"IKS1EJom7qMH"}},{"cell_type":"code","source":["plt.scatter(X_train,y_train , c='black' ,label='Train')\n","plt.scatter(X_test,y_test , c='red' ,label='Test')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"KvF6COah7t8k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Regression Model\n","\n","---"],"metadata":{"id":"QgUGP2US8hpM"}},{"cell_type":"markdown","source":["# Architecture of the Neural Network"],"metadata":{"id":"LkvWRheH9D-r"}},{"cell_type":"code","source":["model = Sequential()\n","\n","model.add(Dense(128,activation='relu',input_dim=1))        # we have 1 input , 128 neurons\n","                                                           # 1 hidden layer\n","model.add(Dense(128,activation='relu'))\n","model.add(Dense(1,activation='linear'))                    # output layer    with activation function linear as\n","                                                           #as it is regression problem\n"],"metadata":{"id":"_koZKJ0A8k_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"_l6dphgA9301"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fitting the Model"],"metadata":{"id":"ylGXE2oXj6i9"}},{"cell_type":"code","source":["\n","adam=keras.optimizers.Adam(learning_rate=0.001)                      #learning rate = 0.001\n","model.compile(optimizer=adam,loss='mse' ,metrics=['mse'])            # we are working with mean squared error ,\n","\n","\n"," # #mse - means squared error , it actualltes accuracy on the basis of MSE"],"metadata":{"id":"lFfF23cy93uA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Accuracy and Prediction!!!"],"metadata":{"id":"4eW1oJBk-clE"}},{"cell_type":"code","source":["history = model.fit(X_train,y_train,epochs=500,validation_data=(X_test,y_test), verbose=False)"],"metadata":{"id":"p6Nkanna-ir5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluate the model"],"metadata":{"id":"rUOk80aH-uF7"}},{"cell_type":"code","source":["# evaluate the model\n","_, train_mse = model.evaluate(X_train, y_train, verbose=0)\n","_, test_mse = model.evaluate(X_test, y_test, verbose=0)\n","print('Train: {}, Test: {}'.format(train_mse, test_mse))"],"metadata":{"id":"1Dn7jgkiAzyC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(X_test)"],"metadata":{"id":"T6jCvHZKjfN8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Plotting the Graph"],"metadata":{"id":"jRoK8nMkkZq2"}},{"cell_type":"markdown","source":["HERE WE CAN CLEARLY SEE THE PROBLEM OF OVERFITTING AS RED THATS IS THE TRAINING SET , REGRESSION LINE CONNECTS IT VERY WELL\n","\n","BUT\n","\n","Blue dots that is the test data most of them doesnot get connected at all ----- pure case of overfitting ."],"metadata":{"id":"fNM842khmvlx"}},{"cell_type":"code","source":["plt.figure()\n","plt.scatter(X_train, y_train, c='red', label='Train')\n","plt.scatter(X_test, y_test, c='blue', label='Test')\n","plt.plot(X_test, y_pred)\n","plt.legend()\n","plt.ylim((-1.5, 1.5))\n","plt.show()"],"metadata":{"id":"DLq8OiDokdnr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dropout Model - REGRESSION"],"metadata":{"id":"sV4BrGS3kprL"}},{"cell_type":"markdown","source":["Architecture of the NN"],"metadata":{"id":"FxXKr83WlI5D"}},{"cell_type":"code","metadata":{"id":"_vOPbuYHSlZm"},"source":["model_2 = Sequential()\n","\n","\n","model_2.add(Dense(128, input_dim=1, activation=\"relu\"))      # We are going to drop 20 percent of the input layer\n","model_2.add(Dropout(0.2))\n","model_2.add(Dense(128, activation=\"relu\"))\n","model_2.add(Dropout(0.2))                                    # we are going to drop 20 percent of the hidden layer\n","model_2.add(Dense(1, activation=\"linear\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fitting the model"],"metadata":{"id":"orWS479nlMET"}},{"cell_type":"code","source":["adam = Adam(learning_rate=0.01)\n","model_2.compile(loss='mse', optimizer=adam, metrics=['mse'])          # Same mean squared error as before"],"metadata":{"id":"C44yWy8Bk2sD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Validating the model"],"metadata":{"id":"1YtylcQilP-b"}},{"cell_type":"code","source":["\n","drop_out_history = model_2.fit(X_train, y_train, epochs=500,\n","                               validation_data = (X_test, y_test),         #we are validating in the test set\n","                               verbose=False)"],"metadata":{"id":"5gFZ6kIhk1c3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluating the model on testing data"],"metadata":{"id":"5C2Pxz-jlYgn"}},{"cell_type":"code","source":["_, train_mse = model_2.evaluate(X_train, y_train, verbose=0)\n","_, test_mse = model_2.evaluate(X_test, y_test, verbose=0)\n","print('Train: {}, Test: {}'.format(train_mse, test_mse))"],"metadata":{"id":"MevHnsRVlgeA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Prediction"],"metadata":{"id":"8kdgOxg6lhWT"}},{"cell_type":"code","source":["y_pred_2 = model_2.predict(X_test)"],"metadata":{"id":"WkrFeWWklkFH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Graph of the DropOut model"],"metadata":{"id":"SGEjWQszlnLG"}},{"cell_type":"code","source":["plt.figure()\n","plt.scatter(X_train, y_train, c='red', label='Train')\n","plt.scatter(X_test, y_test, c='blue', label='Test')\n","plt.plot(X_test, y_pred_2)\n","plt.legend()\n","plt.ylim((-1.5, 1.5))\n","plt.show()"],"metadata":{"id":"uPqLk_FylwlG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MSE for the Normal regression model\n","ON TRAINING SET -- 0.9 PERC\n","ON TEST SET -- 3.6 PERC\n","\n","MSE for the DROPOUT Regression Model\n","On TRAINING SET -- 1.2 PERC\n","ON TEST SET --  4 PERC\n","\n","SO THE DIFFERENCE BETWEEN THE TRAINING SET AND TEST SET OF THE NORMAL REGRESSION MODEL IS WAY MORE\n","\n","COMPARED TO THE DIFFERENCE BETWEEN THE TRAINING SET AND TEST SET OF THE DROPOUT REGRESSION MODEL\n","\n","OVERFITTING HAS BEEN DECREASED SIGNIFICANTLY\n"],"metadata":{"id":"-Iqb4Xufnn0I"}},{"cell_type":"code","source":[],"metadata":{"id":"Y0TvrlK1oiIo"},"execution_count":null,"outputs":[]}]}