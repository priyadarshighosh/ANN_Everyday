{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1PKPhXIs5EjgeKBIDrt6_Ai-zDXRmKcPp","timestamp":1726134581910},{"file_id":"1RO_zr_tQ3BNsXnC3GhDtgR0KuMPaUI7_","timestamp":1726122299987},{"file_id":"1ahyTCXn-3LXAXyJkvqVyfqNlQ4Eex31M","timestamp":1726057833443},{"file_id":"1sUMvMIQRQaOZ9J_H8sHaj9zr3VH34vdK","timestamp":1725989843585}],"authorship_tag":"ABX9TyMfxes8f1IYJQzeeZ/Y8Q0Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# DROPOUT LAYERS\n","\n","# CLASSIFICATION  Implementation"],"metadata":{"id":"buV9E0bf-37g"}},{"cell_type":"markdown","source":["IMPORTING THE DATA SCIENCE LIBRARIES"],"metadata":{"id":"HNvHInaq_BMJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eum2WGOnBeeL"},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import time"]},{"cell_type":"markdown","source":["Importing the ML / Scikit learn EVERYTHING"],"metadata":{"id":"egI1aKHM_G4g"}},{"cell_type":"code","source":["\n","from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n","from sklearn.compose import ColumnTransformer                       #for transforming the columns\n","from sklearn.impute import SimpleImputer                             #for imputing the missing values\n","from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n","from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n","\n","from sklearn.linear_model import LinearRegression                    #linear regression\n","from sklearn.pipeline import Pipeline,make_pipeline                    #here we wont use pipelines\n","\n","from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error     #to calculate the loss function"],"metadata":{"id":"v-A2uAybzaKX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Importing Deep learning Everything"],"metadata":{"id":"7EOOII0y82hE"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"O1qjFngb87Y8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset Generation"],"metadata":{"id":"ADdQQGes_Sdp"}},{"cell_type":"markdown","source":["This is our HAND-MADE DATASET"],"metadata":{"id":"sGKaQv4Ul99C"}},{"cell_type":"code","source":["X = np.array([[-1.58986e-01,  4.23977e-01],\n","       [-3.47926e-01,  4.70760e-01],\n","       [-5.04608e-01,  3.53801e-01],\n","       [-5.96774e-01,  1.14035e-01],\n","       [-5.18433e-01, -1.72515e-01],\n","       [-2.92627e-01, -2.07602e-01],\n","       [-1.58986e-01, -4.38596e-02],\n","       [-5.76037e-02,  1.43275e-01],\n","       [-7.14286e-02,  2.71930e-01],\n","       [-2.97235e-01,  3.47953e-01],\n","       [-4.17051e-01,  2.01754e-01],\n","       [-4.40092e-01,  8.77193e-03],\n","       [-3.24885e-01, -3.21637e-02],\n","       [-2.46544e-01,  5.55556e-02],\n","       [-2.18894e-01,  2.01754e-01],\n","       [-3.43318e-01,  1.60819e-01],\n","       [-5.09217e-01,  7.89474e-02],\n","       [-3.84793e-01, -9.06433e-02],\n","       [-1.49770e-01,  1.25731e-01],\n","       [-1.95853e-01,  3.24561e-01],\n","       [-3.91705e-02, -2.19298e-01],\n","       [-1.08295e-01, -3.01170e-01],\n","       [-1.86636e-01, -3.30409e-01],\n","       [-2.18894e-01, -4.23977e-01],\n","       [-8.06452e-02, -5.64327e-01],\n","       [ 6.68203e-02, -5.17544e-01],\n","       [ 9.44700e-02, -3.24561e-01],\n","       [ 1.86636e-01, -1.66667e-01],\n","       [ 6.22120e-02, -7.30994e-02],\n","       [ 2.07373e-02, -1.95906e-01],\n","       [ 2.99539e-02, -3.42105e-01],\n","       [-9.90783e-02, -3.77193e-01],\n","       [-6.91244e-03, -4.64912e-01],\n","       [ 1.31336e-01, -4.29825e-01],\n","       [ 2.32719e-01, -1.95906e-01],\n","       [ 8.52535e-02, -8.47953e-02],\n","       [-1.31336e-01, -2.36842e-01],\n","       [ 2.30415e-03, -1.25731e-01],\n","       [ 1.22120e-01, -2.92398e-03],\n","       [-3.47926e-01, -3.12865e-01],\n","       [-2.28111e-01, -1.25731e-01],\n","       [-7.60369e-02,  1.46199e-02],\n","       [ 4.37788e-02,  2.04678e-02],\n","       [ 1.15207e-02,  1.54971e-01],\n","       [-4.17051e-01, -1.60819e-01],\n","       [-3.15668e-01, -3.18713e-01],\n","       [ 1.26728e-01, -2.19298e-01],\n","       [ 2.05069e-01, -3.12865e-01],\n","       [ 2.18894e-01, -4.59064e-01],\n","       [ 7.14286e-02, -6.46199e-01],\n","       [-1.31336e-01, -6.05263e-01],\n","       [-2.09677e-01, -5.81871e-01],\n","       [-2.28111e-01, -4.29825e-01],\n","       [-1.45161e-01, -4.12281e-01],\n","       [-6.68203e-02, -4.82456e-01],\n","       [ 1.35945e-01, -5.11696e-01],\n","       [ 2.69585e-01, -4.06433e-01],\n","       [ 2.97235e-01, -2.95322e-01],\n","       [ 2.74194e-01, -1.72515e-01],\n","       [ 2.55760e-01, -4.97076e-02],\n","       [ 2.23502e-01, -4.97076e-02],\n","       [ 1.82028e-01, -8.47953e-02],\n","       [ 1.58986e-01, -1.54971e-01],\n","       [ 7.14286e-02, -2.13450e-01],\n","       [ 1.61290e-02, -2.66082e-01],\n","       [-2.53456e-02, -3.83041e-01],\n","       [-1.15207e-02, -4.82456e-01],\n","       [-2.30415e-03, -5.05848e-01],\n","       [ 2.53456e-02, -5.11696e-01],\n","       [ 2.53456e-02, -5.58480e-01],\n","       [ 1.15207e-02, -6.57895e-01],\n","       [-4.83871e-02, -6.46199e-01],\n","       [-8.52535e-02, -5.52632e-01],\n","       [-9.90783e-02, -5.00000e-01],\n","       [-1.61290e-02, -4.23977e-01],\n","       [ 1.31336e-01, -3.59649e-01],\n","       [ 2.23502e-01, -3.71345e-01],\n","       [ 2.92627e-01, -3.01170e-01],\n","       [ 2.60369e-01, -2.07602e-01],\n","       [ 2.00461e-01, -2.25146e-01],\n","       [ 1.72811e-01, -2.71930e-01],\n","       [-1.31336e-01,  9.06433e-02],\n","       [-1.49770e-01,  7.30994e-02],\n","       [-2.41935e-01,  6.14035e-02],\n","       [-3.01843e-01,  1.78363e-01],\n","       [-2.97235e-01,  1.95906e-01],\n","       [-2.74194e-01,  3.07018e-01],\n","       [-3.24885e-01,  2.95322e-01],\n","       [-3.98618e-01,  2.66082e-01],\n","       [-4.35484e-01,  1.60819e-01],\n","       [-4.72350e-01,  7.89474e-02],\n","       [-3.38710e-01,  4.38596e-02],\n","       [-2.69585e-01,  4.38596e-02],\n","       [-2.55760e-01,  1.02339e-01],\n","       [-1.68203e-01,  2.66082e-01],\n","       [-1.12903e-01,  3.01170e-01],\n","       [-3.91705e-02,  3.47953e-01],\n","       [-1.26728e-01,  4.41520e-01],\n","       [-2.32719e-01,  4.41520e-01],\n","       [-3.38710e-01,  4.18129e-01],\n","       [-4.12442e-01,  3.53801e-01],\n","       [-5.09217e-01,  2.19298e-01],\n","       [-5.41475e-01,  1.46199e-02],\n","       [-5.04608e-01, -1.25731e-01],\n","       [-4.90783e-01, -1.43275e-01],\n","       [-3.61751e-01, -1.37427e-01],\n","       [-2.69585e-01, -8.47953e-02],\n","       [-2.23502e-01, -7.89474e-02],\n","       [-1.86636e-01, -3.80117e-02],\n","       [-1.54378e-01, -8.77193e-03],\n","       [-1.12903e-01,  5.55556e-02],\n","       [-8.52535e-02,  1.37427e-01],\n","       [-8.52535e-02,  2.77778e-01],\n","       [-1.68203e-01,  3.01170e-01],\n","       [-1.91244e-01,  1.95906e-01],\n","       [-1.40553e-01, -4.97076e-02],\n","       [-2.99539e-02,  6.72515e-02],\n","       [-2.00461e-01, -2.30994e-01],\n","       [-1.08295e-01, -8.47953e-02],\n","       [ 3.45622e-02,  6.72515e-02],\n","       [ 8.06452e-02,  1.19883e-01],\n","       [-3.85369e-01,  3.30409e-02],\n","       [-3.81221e-01,  1.31287e-01],\n","       [-3.52189e-01,  2.58187e-01],\n","       [-3.54263e-01,  3.64620e-01],\n","       [-4.14401e-01, -6.92982e-02],\n","       [-4.99424e-01, -3.24561e-02],\n","       [-2.98272e-01, -9.79532e-02],\n","       [-3.16935e-01, -1.83918e-01],\n","       [-3.68779e-01, -2.90351e-01],\n","       [-3.56336e-01, -3.96784e-01],\n","       [-2.71313e-01,  4.38596e-03],\n","       [-1.77995e-01,  8.62573e-02],\n","       [-2.46429e-01,  1.43567e-01],\n","       [-2.50576e-01,  2.29532e-01],\n","       [-2.21544e-01,  3.76901e-01],\n","       [-2.15323e-01,  2.95029e-01],\n","       [-1.30300e-01,  2.17251e-01],\n","       [-2.07028e-01,  2.89474e-02],\n","       [-9.71198e-02,  2.13158e-01],\n","       [-3.90553e-02,  2.58187e-01],\n","       [ 1.90092e-02,  4.01462e-01],\n","       [-3.69816e-02,  4.21930e-01],\n","       [-6.39401e-02,  3.31871e-01],\n","       [-1.30300e-01,  3.76901e-01],\n","       [-3.75000e-01, -4.37719e-01],\n","       [-3.95737e-01, -3.51754e-01],\n","       [-3.54263e-01, -2.08480e-01],\n","       [-4.37212e-01, -3.76316e-01],\n","       [-4.80760e-01, -5.03216e-01],\n","       [-4.10253e-01, -4.66374e-01],\n","       [-2.48502e-01, -2.57602e-01],\n","       [-2.27765e-01, -3.14912e-01],\n","       [-2.83756e-01, -3.84503e-01],\n","       [-2.92051e-01, -4.54094e-01],\n","       [-3.37673e-01, -5.19591e-01],\n","       [-2.77535e-01, -5.48246e-01],\n","       [-2.07028e-01, -5.35965e-01],\n","       [-1.86290e-01, -4.78655e-01],\n","       [-1.32373e-01, -5.07310e-01],\n","       [-1.77995e-01, -2.98538e-01],\n","       [-1.65553e-01, -1.75731e-01],\n","       [-1.61406e-01, -1.26608e-01],\n","       [ 3.45622e-04,  2.58187e-01],\n","       [ 7.91475e-02,  3.56433e-01],\n","       [-2.66129e-02,  1.80409e-01],\n","       [-5.35714e-02,  7.80702e-02],\n","       [-1.41705e-02, -5.29240e-02],\n","       [-7.01613e-02, -1.63450e-01],\n","       [-6.39401e-02, -2.94444e-01],\n","       [-3.07604e-02, -4.66374e-01],\n","       [-5.77189e-02, -5.27778e-01],\n","       [-5.35714e-02, -3.96784e-01],\n","       [ 5.21889e-02, -4.17251e-01],\n","       [-1.62442e-02, -1.67544e-01],\n","       [-6.39401e-02, -8.56725e-02],\n","       [-6.18664e-02, -1.60819e-02],\n","       [-3.80184e-03,  4.38596e-03],\n","       [ 4.18203e-02,  2.04971e-01],\n","       [ 7.91475e-02,  1.92690e-01],\n","       [ 4.59677e-02,  2.54094e-01],\n","       [ 1.18548e-01,  1.92690e-01],\n","       [ 1.10253e-01,  8.62573e-02],\n","       [ 1.08180e-01, -6.92982e-02],\n","       [ 1.66244e-01, -2.42690e-02],\n","       [ 1.41359e-01,  6.57895e-02],\n","       [ 1.43433e-01,  1.68129e-01],\n","       [ 1.70392e-01,  1.92690e-01],\n","       [ 1.08180e-01,  2.99123e-01],\n","       [ 1.18548e-01,  3.19591e-01],\n","       [ 1.26843e-01,  3.93275e-01],\n","       [-8.67512e-02,  4.21930e-01],\n","       [-4.73502e-02,  5.07895e-01],\n","       [ 2.52304e-02,  5.20175e-01],\n","       [ 6.25576e-02,  5.52924e-01],\n","       [-5.87558e-03,  4.42398e-01],\n","       [-5.14977e-02,  5.73392e-01],\n","       [-8.05300e-02,  5.07895e-01],\n","       [-1.53111e-01,  5.52924e-01],\n","       [-1.11636e-01,  5.48830e-01],\n","       [-1.63479e-01,  4.91520e-01],\n","       [-2.52650e-01, -1.88012e-01],\n","       [-2.46429e-01, -3.65497e-02],\n","       [-3.21083e-01, -4.33626e-01],\n","       [-3.31452e-01, -6.05556e-01],\n","       [-3.85369e-01, -5.15497e-01],\n","       [-3.99885e-01, -6.21930e-01],\n","       [-1.24078e-01, -1.26608e-01],\n","       [-3.16935e-01, -2.28947e-01],\n","       [-2.94124e-01, -1.34795e-01],\n","       [-1.53111e-01,  1.84503e-01]])"],"metadata":{"id":"ap9YA65HpVxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = np.array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n","       0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","       0., 1., 1., 1., 1., 0., 0.])"],"metadata":{"id":"8InEQ4AnpmLV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plotting the Graph for the Data-set"],"metadata":{"id":"aQWf3Hltpr8w"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.scatter(X[:,0], X[:,1], c=y)\n","plt.show()"],"metadata":{"id":"1yA3yKhJpsm2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Classification Model\n","\n","---"],"metadata":{"id":"QgUGP2US8hpM"}},{"cell_type":"markdown","source":["# Architecture of the Neural Network"],"metadata":{"id":"LkvWRheH9D-r"}},{"cell_type":"code","source":["model = Sequential()\n","\n","model.add(Dense(128,activation='relu',input_dim=2))        # we have 1 input , 128 neurons\n","                                                           # 1 hidden layer\n","model.add(Dense(128,activation='relu'))\n","model.add(Dense(1,activation='sigmoid'))                    # output layer    with activation function linear as\n","                                                           #as it is classification  problem\n"],"metadata":{"id":"_koZKJ0A8k_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"_l6dphgA9301"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fitting the Model"],"metadata":{"id":"ylGXE2oXj6i9"}},{"cell_type":"code","source":["\n","adam=keras.optimizers.Adam(learning_rate=0.01)                      #learning rate = 0.01\n","model.compile(optimizer=adam,loss='binary_crossentropy' ,metrics=['accuracy'])            # we are working with mean squared error ,\n","\n","\n"," # binary crossentropy because we have 2 colors dots and we have to separate those"],"metadata":{"id":"lFfF23cy93uA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Accuracy and Prediction!!!"],"metadata":{"id":"4eW1oJBk-clE"}},{"cell_type":"markdown","source":["cross validation is being done on 20 perc of the data"],"metadata":{"id":"2Ehm311vqdHC"}},{"cell_type":"markdown","source":["We fit the X and y data into the model"],"metadata":{"id":"X453bhw5rBF2"}},{"cell_type":"code","source":["history = model.fit(X,y,epochs=500,validation_split=0.2, verbose=False)"],"metadata":{"id":"p6Nkanna-ir5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Plotting the Graph"],"metadata":{"id":"jRoK8nMkkZq2"}},{"cell_type":"markdown","source":["HERE WE CAN CLEARLY SEE THE PROBLEM OF OVERFITTING AS\n","\n","ORANGE DOT GONNA COMPLETLY COVER CALL THE ORANGE DOTS\n","BUT\n","\n"," BLUE DOTS ALSO BE COVERED VERY EFFICIENTLY\n","\n"," MEANING - MODEL WORKS JUST FINE ON THE TRAINING DATASET , BUT IT DOESNOT WORK PROPERLY ON THE TEST SET\n","\n","\n"," -- CASE OF OVER-FITTING"],"metadata":{"id":"fNM842khmvlx"}},{"cell_type":"code","source":["from mlxtend.plotting import plot_decision_regions"],"metadata":{"id":"PtNxzgH2sfTc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_decision_regions(X, y.astype('int'), clf=model, legend=2)\n","plt.xlim(-0.7,0.5)\n","plt.ylim(-0.8,0.8)\n","plt.show()"],"metadata":{"id":"QACclJnmsg0j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The more is the differnce between the validation loss and real loss\n","\n","the more is the MODEL over-fitted"],"metadata":{"id":"K4ZzA-hastes"}},{"cell_type":"code","source":["plt.plot(history.history['loss'])                 #plotting the loss\n","\n","plt.plot(history.history['val_loss'])               #plotting the validation loss\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"GlFICkJwsmBZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["IN training they are showing soo less loss but then again if we test it .... CLASSIFICATION GOES HAYWARE LOSS INCREASES EXPONENTIALLY"],"metadata":{"id":"zNlPehNAs5Ky"}},{"cell_type":"code","source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"yylKLE_vs43s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["IN training they are showing AROUND 100 ACCURACY\n"," but\n","\n"," if we test it  THE ACCURACY VARIES FROM 80 PERC TO 85 PERC"],"metadata":{"id":"Ebk4knqFteNY"}},{"cell_type":"markdown","source":["# Dropout Model - REGRESSION"],"metadata":{"id":"sV4BrGS3kprL"}},{"cell_type":"markdown","source":["Architecture of the NN"],"metadata":{"id":"FxXKr83WlI5D"}},{"cell_type":"code","metadata":{"id":"_vOPbuYHSlZm"},"source":["model_2 = Sequential()\n","\n","\n","model_2.add(Dense(128, input_dim=2, activation=\"relu\"))      # We are going to drop 50 percent of the input layer\n","model_2.add(Dropout(0.5))\n","model_2.add(Dense(128, activation=\"relu\"))\n","model_2.add(Dropout(0.5))                                    # we are going to drop 50 percent of the hidden layer\n","model_2.add(Dense(1, activation=\"sigmoid\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"HfHVGizBwzEi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fitting the model"],"metadata":{"id":"orWS479nlMET"}},{"cell_type":"code","source":["adam = Adam(learning_rate=0.01)\n","model_2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])          # Same mean squared error as before"],"metadata":{"id":"C44yWy8Bk2sD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Validating the model"],"metadata":{"id":"1YtylcQilP-b"}},{"cell_type":"code","source":["\n","history = model_2.fit(X, y, epochs=500,\n","                               validation_split=0.2,         #we are validating in the test set\n","                               verbose=1)"],"metadata":{"id":"5gFZ6kIhk1c3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Graph of the Drop-Out model"],"metadata":{"id":"SGEjWQszlnLG"}},{"cell_type":"markdown","source":["MSE for the Normal regression model\n","ON TRAINING SET -- 0.1 PERC\n","ON TEST SET -- 3.6 PERC\n","\n","MSE for the DROPOUT Regression Model\n","On TRAINING SET -- 1.2 PERC\n","ON TEST SET --  4 PERC\n","\n","SO THE DIFFERENCE BETWEEN THE TRAINING SET AND TEST SET OF THE NORMAL REGRESSION MODEL IS WAY MORE\n","\n","COMPARED TO THE DIFFERENCE BETWEEN THE TRAINING SET AND TEST SET OF THE DROPOUT CLASSIFICATION MODEL\n","\n","OVERFITTING HAS BEEN DECREASED SIGNIFICANTLY\n"],"metadata":{"id":"-Iqb4Xufnn0I"}},{"cell_type":"code","source":["plot_decision_regions(X, y.astype('int'), clf=model_2, legend=2)\n","plt.xlim(-0.7,0.5)\n","plt.ylim(-0.8,0.8)\n","plt.title('p = 0.5')\n","plt.show()"],"metadata":{"id":"Y0TvrlK1oiIo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"f4fG-U05x2w3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"jguRDS-zx2oo"},"execution_count":null,"outputs":[]}]}