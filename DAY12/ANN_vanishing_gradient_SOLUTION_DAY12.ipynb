{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPF5vHhHAGTgSCOe4sTnth9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyadarshighosh/ANN_Everyday/blob/main/DAY12/ANN_vanishing_gradient_SOLUTION_DAY12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  SOLUTION FOR VANISHING GRADIENT PROBLEM"
      ],
      "metadata": {
        "id": "2zdnFnEa3u93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing the python libraries , sklearn and keras stuff"
      ],
      "metadata": {
        "id": "oBlPwGI630Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "-zJ9b3gptd9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UxaUuGR5tfJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "94EJEOBZtjb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Called Make Moons Function to make a Classification dataset"
      ],
      "metadata": {
        "id": "z_0ZYMWdtvZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = make_moons(n_samples=250, noise=0.05, random_state=42)"
      ],
      "metadata": {
        "id": "YHI56EcEt7EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:,0],X[:,1], c=y, s=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-yzcHyOYt_hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ARCHITECHTURE OF THE Neural Network"
      ],
      "metadata": {
        "id": "xPM02HGwuDSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Neural Network-\n",
        "We have 1 input layer , 1 output layer\n",
        "\n",
        "and Many hidden layer with 10 neurons each with activation function = relu .\n"
      ],
      "metadata": {
        "id": "G0QGtcq_uWTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(10,activation='relu',input_dim=2))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "jHQhr14iuR0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])   #model compilation"
      ],
      "metadata": {
        "id": "Ao89vA4Rvszc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()  #this gonna show the values of the weights / baises initialized randomly by the model"
      ],
      "metadata": {
        "id": "Cz8L5Vl0v0YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()[0] #we are getting the 1st weight and we gonna store it in a variable"
      ],
      "metadata": {
        "id": "QbdjcZ1Uv6Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_weights = model.get_weights()[0]"
      ],
      "metadata": {
        "id": "X0g9hcd9wVjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN / TEST SPLIT"
      ],
      "metadata": {
        "id": "65iTIKbgwbw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "QThvxiYpwkqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_jna0zgIwrOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FITTING THE DATA INTO THE ARCHITECHTURE"
      ],
      "metadata": {
        "id": "Qf-7BTexwu6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs = 100)"
      ],
      "metadata": {
        "id": "ouf7UIKiV7hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "later we will compare old_weights and new_weights thats why we are storing both the values"
      ],
      "metadata": {
        "id": "31P8IfKlxuUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_weights = model.get_weights()[0] #storing  the 1st new weights after fitting the data into the model"
      ],
      "metadata": {
        "id": "bTiX03Icw8vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.optimizer.get_config()['learning_rate']      #optimizer configuration- this gonna give us the leaarning rate"
      ],
      "metadata": {
        "id": "Em3sIILcxHer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating gradient , percent_change , new-weights and old_weights"
      ],
      "metadata": {
        "id": "9zv2LWwOx-WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gradient = (new_weights - old_weights) / 0.001      #as new = old - learning-rate X gradient\n",
        "percent_change = abs(100*(new_weights - old_weights) / old_weights )       #percentage change in the weights from old to new"
      ],
      "metadata": {
        "id": "zMwtQI9ayN_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient"
      ],
      "metadata": {
        "id": "sREg4QJyyioX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percent_change                   #this is the percentage change between the old_weights and new_weights"
      ],
      "metadata": {
        "id": "97zYpIrGykeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The percentage change is QUITE GOOD its in 2digits for most of the weights , GREAT SIGN"
      ],
      "metadata": {
        "id": "m0K1ogVV25BN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparison between old weights and new weights , its SIGNIFICANT"
      ],
      "metadata": {
        "id": "slfbyn-c2_z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "old_weights"
      ],
      "metadata": {
        "id": "jN7-PT2aymkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_weights"
      ],
      "metadata": {
        "id": "aH_iM8QnyoKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS THERE IS NO SIGNIFICANT CHANGE BETWEEN THE old_weights and the new_weights , WE CAN SAY VANISHING GRADIENT DESCENT HAS BEEN SOLVED BECAUSE WE ADDED THE RELU FUNCTION"
      ],
      "metadata": {
        "id": "sr4AeDNx37Y-"
      }
    }
  ]
}